---
subtitle: "Part 2A, Regression - Baseline Models"
author: "Zhenyu Li"
date: '2022-04-08'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(coefplot)
source("./scripts/utils.R")
theme_set(theme_linedraw())
```

```{r message=FALSE, warning=FALSE}
df <- readr::read_csv("./data/final_project_train.csv", col_names = TRUE)
sel_num <- df %>% select_if(is_double) %>% select(!rowid) %>% select(sort(names(.))) %>% colnames()
sel_num_in <- setdiff(sel_num,"response")
sel_cat <- df %>% select(!one_of(sel_num)) %>% select(!rowid) %>% colnames()
sel_cat_in <- setdiff(sel_cat, "outcome")
```

----

## Preprocessing

- For regression, the necessary preprocessing steps include:  
  - Log-transform the continuous response  
  - Standardize continuous inputs  

```{r}
df_preproc <- df %>% 
  mutate_if(is.character,as.factor) %>% 
  select(-c(rowid,outcome)) %>% 
  mutate(
    response = log(response),
    across(starts_with("x"), scale)
  )
```


## Model Fitting

### Predefined Models

- Fit the following models  
  1. Categorical variables only – linear additive  
  2. Continuous variables only – linear additive  
  3. All categorical and continuous variables – linear additive  
  4. Interact `region` with continuous inputs, do not include `customer`  
  5. Interact `customer` with continuous inputs, do not include `region`  
  6. All pairwise interactions of continuous inputs, do not include categorical inputs  

- Slice the data with certain inputs to facilitate model building.   

```{r}
df_cat <- df_preproc %>% select(-all_of(sel_num_in))
df_num <- df_preproc %>% select(-all_of(sel_cat_in))
```

- Fit models by providing specific formula.  

```{r}
mod_2A1 <- lm(response ~ ., df_cat)
mod_2A2 <- lm(response ~ ., df_num)
mod_2A3 <- lm(response ~ ., df_preproc)
mod_2A4 <- lm(response ~ region * (. -customer), df_preproc)
mod_2A5 <- lm(response ~ customer * (. -region), df_preproc)
mod_2A6 <- lm(response ~ (.)^2, df_num)
```

- Get a quick comparison using information criterion.  

```{r}
my_models <- mget(ls(pattern = "^mod_2A\\d+"))
calc_models_ic(my_models)
```

- `mod_2A3`: Additive relationship of all continuous inputs got best BIC.  
- `mod_2A4`: Adding interaction from `region` seem to improve AIC at the cost of BIC.   

### Custom Basis Models

- Fit 6 custom basis models

- Input features that involve some non-linearity from EDA are
  - `xa, xb, xn` at index `03, 05, 08`
  - `xs` index `01, 04, 06`
  - `xw` index `01, 02, 03`

- Add non-linearity using quadratic (2 degree polynomial) to these inputs, keep linear for the rest.
  - Use linear additive relationships for all features.

```{r model 2AC1}
mod_2AC1 <- lm(
  response ~ . + 
    + splines::ns(xa_03,df=2) + splines::ns(xa_05,df=2) + splines::ns(xa_08,df=2) - xa_03 - xa_05 - xa_08 
    + splines::ns(xb_03,df=2) + splines::ns(xb_05,df=2) + splines::ns(xb_08,df=2) - xb_03 - xb_05 - xb_08 
    + splines::ns(xn_03,df=2) + splines::ns(xn_05,df=2) + splines::ns(xn_08,df=2) - xn_03 - xn_05 - xn_08
    + splines::ns(xs_01,df=2) + splines::ns(xs_04,df=2) + splines::ns(xs_06,df=2) - xs_01 - xs_04 - xs_06
    + splines::ns(xw_01,df=2) + splines::ns(xw_02,df=2) + splines::ns(xw_03,df=2) - xw_01 - xw_02 - xw_03
  , df_preproc)
calc_models_ic(list(mod_2AC1))
```

- Add interaction from region and customer, keep the rest as 2AC1.  

```{r model 2AC2}
mod_2AC2 <- lm(
    response ~ region * customer + .
    + splines::ns(xa_03,df=2) + splines::ns(xa_05,df=2) + splines::ns(xa_08,df=2) - xa_03 - xa_05 - xa_08 
    + splines::ns(xb_03,df=2) + splines::ns(xb_05,df=2) + splines::ns(xb_08,df=2) - xb_03 - xb_05 - xb_08 
    + splines::ns(xn_03,df=2) + splines::ns(xn_05,df=2) + splines::ns(xn_08,df=2) - xn_03 - xn_05 - xn_08
    + splines::ns(xs_01,df=2) + splines::ns(xs_04,df=2) + splines::ns(xs_06,df=2) - xs_01 - xs_04 - xs_06
    + splines::ns(xw_01,df=2) + splines::ns(xw_02,df=2) + splines::ns(xw_03,df=2) - xw_01 - xw_02 - xw_03
  , df_preproc)
calc_models_ic(list(mod_2AC2))
```

- Interact `region` with the nonlinear features from 2AC1, additive for the rest. 

```{r model 2AC3}
mod_2AC3 <- lm(
  response ~ . + region :
    ( splines::ns(xa_03,df=2) + splines::ns(xa_05,df=2) + splines::ns(xa_08,df=2)
    + splines::ns(xb_03,df=2) + splines::ns(xb_05,df=2) + splines::ns(xb_08,df=2)
    + splines::ns(xn_03,df=2) + splines::ns(xn_05,df=2) + splines::ns(xn_08,df=2)
    + splines::ns(xs_01,df=2) + splines::ns(xs_04,df=2) + splines::ns(xs_06,df=2)
    + splines::ns(xw_01,df=2) + splines::ns(xw_02,df=2) + splines::ns(xw_03,df=2) ) 
    - xa_03 - xa_05 - xa_08 
    - xb_03 - xb_05 - xb_08 
    - xn_03 - xn_05 - xn_08
    - xs_01 - xs_04 - xs_06
    - xw_01 - xw_02 - xw_03, 
  df_preproc)
calc_models_ic(list(mod_2AC3))
```

-  Interact `region` to the linear inputs from 2AC1, additive for the rest.  

```{r model 2AC4}
mod_2AC4 <- lm(
  response ~ customer + 
    + region : (. - customer 
      - xa_03 - xa_05 - xa_08
      - xb_03 - xb_05 - xb_08
      - xn_03 - xn_05 - xn_08
      - xs_01 - xs_04 - xs_06
      - xw_01 - xw_02 - xw_03 )
    + splines::ns(xa_03,df=2) + splines::ns(xa_05,df=2) + splines::ns(xa_08,df=2) 
    + splines::ns(xb_03,df=2) + splines::ns(xb_05,df=2) + splines::ns(xb_08,df=2) 
    + splines::ns(xn_03,df=2) + splines::ns(xn_05,df=2) + splines::ns(xn_08,df=2)
    + splines::ns(xs_01,df=2) + splines::ns(xs_04,df=2) + splines::ns(xs_06,df=2)
    + splines::ns(xw_01,df=2) + splines::ns(xw_02,df=2) + splines::ns(xw_03,df=2)
  , df_preproc)
calc_models_ic(list(mod_2AC4))
```

- Interact `region` with inputs showing nonlinear relationship to response, but do not use nonlinear basis.  

```{r model 2AC5}
mod_2AC5 <- lm(
  response ~ . + region : (
    + xa_03 + xa_05 + xa_08
    + xb_03 + xb_05 + xb_08
    + xn_03 + xn_05 + xn_08
    + xs_01 + xs_04 + xs_06
    + xw_01 + xw_02 + xw_03 )
    - xa_03 - xa_05 - xa_08 
    - xb_03 - xb_05 - xb_08 
    - xn_03 - xn_05 - xn_08
    - xs_01 - xs_04 - xs_06
    - xw_01 - xw_02 - xw_03, 
  df_preproc)
calc_models_ic(list(mod_2AC5))
```

- Pair-wise interaction for all input variables. 

```{r model 2AC6}
mod_2AC6 <- lm(response ~ (.)^2, df_preproc)
calc_models_ic(list(mod_2AC6))
```

### Save the Models

Save models to file. 

```{r}
my_models <- mget(ls(pattern = "^mod_2A"))
save_models(my_models)
```

----

## Conclusions

```{r}
mod_2A1 <- readr::read_rds("models/mod_2A1")
mod_2A2 <- readr::read_rds("models/mod_2A2")
mod_2A3 <- readr::read_rds("models/mod_2A3")
mod_2A4 <- readr::read_rds("models/mod_2A4")
mod_2A5 <- readr::read_rds("models/mod_2A5")
mod_2A6 <- readr::read_rds("models/mod_2A6")
mod_2AC1 <- readr::read_rds("models/mod_2AC1")
mod_2AC2 <- readr::read_rds("models/mod_2AC2")
mod_2AC3 <- readr::read_rds("models/mod_2AC3")
mod_2AC4 <- readr::read_rds("models/mod_2AC4")
mod_2AC5 <- readr::read_rds("models/mod_2AC5")
mod_2AC6 <- readr::read_rds("models/mod_2AC6")
```

### Model Comparison

Print out the model metrics. 

```{r}
my_models <- mget(ls(pattern = "^mod_2A"))
calc_models_ic(my_models) %>% knitr::kable()
```

- Metrics
  - I will use information criterion (AIC/BIC) for model selection since models are developed from training set without resampling. 

- Special case
  - The all-pairwise model (`mod_2AC6`) resulted negative AIC/BIC. I talked to Dr. Yurko, and he suggests skipping this one for the Bayesian analysis because it will have enormous uncertainty, but including it for resampling (2D). 
  - For here, I will skip it too, and examine models with second lowest AIC, second lowest BIC, and one in between for both.

- Best models
  - Based on the BIC, select `mod_2A3`.
  - Based on the AIC, select `mod_2AC3`. 
  - Based on balance of the two, select `mod_2AC5`

### Coefficient Plot

Visualize the coefficient summaries for the top 3 models. 

```{r out.width=500, fig.width=5, fig.asp=1}
coefplot(mod_2A3)
coefplot(mod_2AC3)
coefplot(mod_2AC5)
```

- Each model contains some significant coefficients, but it looks like majority of them are non-significant.
  - Majority of coefficients are small (within 0.5).  

### Important Features

- Filter each model for significant coefficients (uncertainty interval do not span 0).  
  - Then rank by their estimated coefficients in descending order.  
  - Those with higher coefficients indicate more importance.  

```{r}
pull_lm_coefs_signif(mod_2A3, 0.99)
pull_lm_coefs_signif(mod_2AC3, 0.99)
pull_lm_coefs_signif(mod_2AC5, 0.99)
```

- For categorical inputs, both the `region`, `customer` are important. 
- For continuous inputs, potential important ones are:
  - `xw_01`, `xb_04`, `xb_07`, `xa_02`, `xb_03`, `xs_04`
- It is also notable that interaction from `region` to some inputs are important. 

----
