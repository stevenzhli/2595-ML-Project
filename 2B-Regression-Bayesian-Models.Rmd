---
subtitle: "Part 2B, Regression - Bayesian Models"
author: "Zhenyu Li"
date: '2022-04-12'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_linedraw())
library(rstanarm)
options(mc.cores = parallel::detectCores())
library(corrplot)
source("./scripts/utils.R")
```

```{r message=FALSE, warning=FALSE}
df <- readr::read_csv("./data/final_project_train.csv", col_names = TRUE)
sel_num <- df %>% select_if(is_double) %>% select(!rowid) %>% select(sort(names(.))) %>% colnames()
sel_num_in <- setdiff(sel_num,"response")
sel_cat <- df %>% select(!one_of(sel_num)) %>% select(!rowid) %>% colnames()
sel_cat_in <- setdiff(sel_cat, "outcome")
```

----

## Preprocessing

- For regression, the necessary preprocessing steps include:
  - Log-transform the continuous response
  - Standardize continuous inputs

```{r}
df_preproc <- df %>% 
  mutate_if(is.character,as.factor) %>% 
  select(-c(rowid,outcome)) %>% 
  mutate(
    response = log(response),
    across(starts_with("x"), scale)
  )
```

----

## Bayesian Model Fitting

Select two models from 2A for Bayesian model fitting. 
- Select models `mod_2A3` and `mod_2AC3`. 
  - Model `mod_2A3` is best model according to BIC, which consist of only linear additive of linear inputs. 
  - Model `mod_2AC3` is best model according to AIC, by adding interaction from `region` to non-linear features. 
  - Model `mod_2AC5` has intermediate AIC/BIC result, by removing the non-linear features while maintaining the interaction. We shall see if this helps to reduce model uncertainty. 
- Use weak prior R-squared of 0.5. 

```{r}
mod_2A3 <- readr::read_rds("models/mod_2A3")
mod_2AC3 <- readr::read_rds("models/mod_2AC3")
mod_2AC5 <- readr::read_rds("models/mod_2AC5")
```


- Based on model `mod_2A3`, with linear additive of all inputs.

```{r model 2B1}
mod_2B1 <- stan_lm(
  mod_2A3$call$formula,
  data=df_preproc,
  prior = R2(location = 0.5),
  seed = 1324
)
```


- Based on model `mod_2AC3`

```{r model 2B2}
mod_2B2 <- stan_lm(
  mod_2AC3$call$formula,
  data=df_preproc, 
  prior = R2(location = 0.5),
  seed = 1324
)
```


- Based on model `mod_2AC5`. 

```{r model 2B3}
mod_2B3 <- stan_lm(
  mod_2AC5$call$formula,
  data=df_preproc, 
  prior = R2(location = 0.5),
  seed = 1324
)
```

### Save the Models

- Save the models to file

```{r}
my_models <- mget(ls(pattern = "^mod_2B"))
save_models(my_models)
```

## Conclusions

```{r}
mod_2B1 <- readr::read_rds("models/mod_2B1")
mod_2B2 <- readr::read_rds("models/mod_2B2")
mod_2B3 <- readr::read_rds("models/mod_2B3")
```

### Model Comparison

- Metrics  
  - I would choose WAIC (information criterion) for model selection, since at this stage we use training set only, without any resampling.  

```{r}
mod_2B1$waic <- waic(mod_2B1)
mod_2B2$waic <- waic(mod_2B2)
mod_2B3$waic <- waic(mod_2B3)
```

```{r}
my_models <- stanreg_list(
  mod_2B1, mod_2B2, mod_2B3,
  model_names = c("2B1, all linear","2B2, region: non-linear","2B3, region: some linear"))
loo_compare(my_models, criterion = "waic")
```

- Based on WAIC, model `mod_2B3` with interaction from `region` to some of the linear features is the best model.   
- For the other two models, the performance difference are both greater than the respective s.e. on the difference from the best model. Thus `mod_2B3` is indeed the best one among the three as identified by WAIC.  


### Best Model

Analyze the posterior behavior of the best model. 

#### R-squared

```{r}
bayes_R2(mod_2B3) %>% quantile(c(0.05, 0.5, 0.95))
```

- Data changed our prior belief about the model uncertainty (R-squared).  
  - Posterior lower 5th quantile at 0.65, while prior belief was 0.5 for R-squared.  

#### Coefficients

- Visualize the regression coefficient posterior summary statistics for your best model.

```{r Uncertainty, out.width=400, fig.width=4, fig.asp=2}
plot(mod_2B3, pars = names(mod_2B3$coefficients)) +
  geom_vline(xintercept = 0, color = "black", linetype = "dashed", size = 0.5)
```


- Check the correlation of the posterior coefficients.  

```{r Correlations, out.width=500, fig.width=5, fig.asp=1, warning=FALSE}
mod_2B3 %>% as_tibble() %>% 
  select(all_of(names(mod_2B3$coefficients))) %>% 
  cor() %>% corrplot(method="color", type="upper")
```

- Some positive correlation of `customers`. 

#### Model Uncertainty

- Tasks  
  - Study the posterior uncertainty in the noise (residual error), ùúé.
  - How does the `lm()` maximum likelihood estimate (MLE) on ùúé relate to the posterior uncertainty on ùúé ?
  - Do you feel the posterior is precise or are we quite uncertain about ùúé

- Visualize the œÉ posterior distribution across all 3 models. 

```{r}
my_models <- mget(ls(pattern = "^mod_2B"))
my_models %>% pull_bayes_posterior_sigma() %>% 
  ggplot(aes(x = sigma)) +
  geom_freqpoly(aes(color = model),bins = 50) +
  geom_vline(xintercept = sigma(mod_2AC5), color="#4D9EFF", linetype="dotted", size=0.5) +
  geom_vline(xintercept = sigma(mod_2B3), color="#4D9EFF", linetype="dashed", size=0.5) +
  geom_vline(xintercept = sigma(mod_2B2), color="#00BE0F", linetype="dashed", size=0.5)
```

- Model `mod_2B2` has the lowest posterior œÉ mode (green dashed line). 
  - The amount of uncertainty is similar for all three models, spanning the range of about 0.04. 
  - Thus the posterior œÉ is fairly precise as none spans a large range. 

- For the best model identified using WAIC `mod_2B3`:
  - The posterior mode of œÉ from the Bayesian model is around 0.299 (blue dashed line).
  - The corresponding MLE estimated œÉ is 0.292 (blue dotted line).
  - The MLE underestimated œÉ: there is 81.2% chance œÉ is greater than the MLE estimate, judging from the posterior samples. 

```{r}
sprintf("Posterior mode œÉ: %.3f", sigma(mod_2B3))
sprintf("MLE estimated œÉ: %.3f", sigma(mod_2AC5))

my_mod_sigma <- mod_2B3 %>% as_tibble() %>% select(sigma)
sprintf("Probability of posterior œÉ > MLE œÉ: %.3f%%", mean(my_mod_sigma >= sigma(mod_2AC5))*100)
```
