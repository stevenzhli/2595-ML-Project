---
title: "INFSCI 2595 Final Project"
subtitle: "Part 2C, Regression - Model Predictions"
author: "Zhenyu Li"
date: '2022-04-15'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_linedraw())
library(rstanarm)
options(mc.cores = parallel::detectCores())
library(bayesplot)
source("./scripts/utils.R")
```

```{r message=FALSE, warning=FALSE}
df <- readr::read_csv("./data/final_project_train.csv", col_names = TRUE)
df_preproc <- df %>%
  mutate_if(is.character,as.factor) %>%
  select(-c(rowid,outcome)) %>%
  mutate(
    response = log(response),
    across(starts_with("x"), scale)
  )
my_inputs <- setdiff(names(df_preproc),"response")
```

----

In this section, I will visualize how selected predictors (inputs) could predict the `response` using the linear models created earlier.  

----

## Preparation

### Model Selection

**Select two Bayesian models from 2B for prediction and visualization.**   

- Choose two with similar posterior Ïƒ but different features:
- One with `region` interacting inputs with non-linear basis (2 dof natural spline) `mod_2B3_2Ac3`.  
  - This is the best model identified using WAIC during Bayesian model fitting.
- One with only linear additive inputs `mod_2B1_2A3`.  
  - This is the best model identified by BIC in MLE model fitting.  

```{r}
mod_2A3 <- readr::read_rds("models/mod_2A3")
mod_2Ac3 <- readr::read_rds("models/mod_2Ac3")
mod_2B1_2A3 <- readr::read_rds("models/mod_2B1_2A3")
mod_2B3_2Ac3 <- readr::read_rds("models/mod_2B3_2Ac3")
```

### Input Selection

**Select inputs to visualize, based on model coefficient significance.**  

**First model, plot significant coefficients.**  

```{r mod_2B3_2Ac3}
mod_2B3_2Ac3 %>% as_tibble() %>%
  select(all_of(
    mod_2Ac3 %>% pull_lm_coefs_signif(top_n = 20) %>% select(coef) %>% unlist(use.names=F)
  )) %>%
  # mcmc_areas_ridges(prob=0.6, prob_outer = 0.9) +
  mcmc_intervals() +
  geom_vline(xintercept = 0,linetype="dashed")
```

- Among these significant coefficients:
  - The linear inputs have much less magnitudes and uncertainties.
  - Interaction between `region` to non-linear features have greater uncertainty, but also greater magnitudes.

**Second model, plot significant coefficients.**  

```{r mod_2B1_2A3}
mod_2B1_2A3 %>% as_tibble() %>%
  select(all_of(
    mod_2A3 %>% pull_lm_coefs_signif(top_n = 15) %>% select(coef) %>% unlist(use.names=F)
  )) %>%
  # mcmc_areas_ridges(prob=0.6, prob_outer = 0.9) +
  mcmc_intervals() +
  geom_vline(xintercept = 0,linetype="dashed")
```

- All linear feature coefficients are quite small compared to the nonlinear predictors from first model `mod_2B3_2Ac3`.

**Choose predictors to use based on both models.**  

- Selection criterion
  1. Since continuous inputs are normalized, the greater magnitude of the estimated coefficient indicates more impact from this input to the `response`.
  2. If two coefficients show significant difference on the coefplot they worth looking at.  
  3. Examine both continuous and categorical inputs.  

- Selected 4 sets of inputs for visualization
  1. xb_07, xb_04
  2. xb_07, customer
  3. xa_08, xb_07, region
  4. xw_01, xb_05, region

- Note: since all continuous inputs are normalized, the prediction test grid is just created at the same scale using the preprocessed dataset. The predictors thus have the normalized scales, not the actual scale from the original data set. But the trends should remain. So is the response, which is log-transformed.  

----

## Predictions

### Set 1: xb_07, xb_04

This set of inputs is associated with the top 2 most important continuous inputs.  

```{r}
viz_grid <- make_test_input_grid(my_inputs, df_preproc, c("xb_07", "xb_04"))
```

**First model**  

```{r mod_2B3.1, out.width=800, fig.width=8, fig.asp=0.24, warning=FALSE}
make_post_pred(mod_2B3_2Ac3, viz_grid) %>% ggplot(aes(x=xb_07, fill=xb_04)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(~xb_04, scales="free_y") +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "xb_04", breaks = NULL, labels = NULL)) +
  scale_fill_viridis_c() + ylab("log response")
```

- The log-response increases with the linear predictor `xb_07` (each fact).
- The log-response decreases with the linear predictor `xb_04` (horizontal facts, shift trends down).
- There is higher uncertainty on the model behavior (mean trend) when inputs are at extreme values.  

**Second model**  

```{r mod_2B1.1, out.width=800, fig.width=8, fig.asp=0.24, warning=FALSE}
viz_grid <- make_test_input_grid(my_inputs, df_preproc, c("xb_07", "xb_04"))

make_post_pred(mod_2B1_2A3, viz_grid) %>% ggplot(aes(x=xb_07, fill=xb_04)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(~xb_04, scales="free_y") +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "xb_04", breaks = NULL, labels = NULL)) +
  scale_fill_viridis_c() + ylab("log response")
```

- Same trends as with the first model.  

### Set 2: xb_07, customer

This set of inputs are selected to examine how the categorical input `customer` affects the ability for the important continuous inputs to predict.  

```{r}
viz_grid <- make_test_input_grid(my_inputs, df_preproc, c("xb_07"), "customer")
```

**First model**  

```{r mod_2B3.2, out.width=800, fig.width=8, fig.asp=0.20, warning=FALSE}
make_post_pred(mod_2B3_2Ac3, viz_grid) %>%
  ggplot(aes(x=xb_07, fill=customer)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(~customer) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "customer", breaks = NULL, labels = NULL)) +
  ylab("log response") + theme(legend.position="none")
```

- The `customer` input affects how the linear predictor `xb_07` predicts the log-response.  
  - Customers `A`,`K` tend to have higher response.  
  - Customers `M`,`Q` tend to have lower response.  

**Second model**  

```{r mod_2B1.2, out.width=800, fig.width=8, fig.asp=0.20, warning=FALSE}
make_post_pred(mod_2B1_2A3, viz_grid) %>%
  ggplot(aes(x=xb_07, fill=customer)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(~customer) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "customer", breaks = NULL, labels = NULL)) +
  ylab("log response") + theme(legend.position="none")
```

- Same trends as with the first model.  

### Set 3: xa_08, xb_07, region

This set of inputs involves the most important linear continuous input (`xb_07`), and the nonlinear continuous input with most magnitude (`xa_08`). I hope to visualize how the two inputs affect the response, at different `region` categories.  

```{r}
viz_grid <- make_test_input_grid(my_inputs, df_preproc, c("xa_08", "xb_07"), "region")
```

**First model**  

```{r mod_2B3.3, out.width=800, fig.width=8, fig.asp=0.6, warning=FALSE}
make_post_pred(mod_2B3_2Ac3, viz_grid) %>%
  ggplot(aes(x=xa_08, fill=xb_07)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(region~xb_07) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "xb_07", breaks = NULL, labels = NULL)) +
  scale_fill_viridis_c() + ylab("log response")
```

- Effect of nonlinear predictor `xa_08` depends on the `region`:
  - In region `XX`, high `xa_08` slightly decreases the log-response;
  - In region `YY`, high `xa_08` greatly decreases the log-response;
  - This input does not have much effect for region `ZZ`.  
- The nonlinear predictors from `xa_08` have large model uncertainties (mean behavior), especially at extreme predictor values.  
  - This may suggest overfit when the inputs are at extremes.  
- Increasing the linear predictor `xb_07` slightly increase the response (horizontal facets).
  - The magnitude of the effect is overshadowed by the nonlinear predictor (the coefficients are small).  

**Second model**  

```{r mod_2B1.3, out.width=800, fig.width=8, fig.asp=0.6, warning=FALSE}
make_post_pred(mod_2B1_2A3, viz_grid) %>%
  ggplot(aes(x=xa_08, fill=xb_07)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(region~xb_07) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "xb_07", breaks = NULL, labels = NULL)) +
  scale_fill_viridis_c() + ylab("log response")
```

- Compared to the first model with `region` interacting with nonlinear features, this linear additive only model is less flexible and unable to adapt to the trend based on `region` because there is no interaction.  
  - All we get is that different `region` shifts the trends up and down.  
- This resulted higher prediction uncertainty but relatively smaller model uncertainty as compared to the other model.  

### Set 4: xw_01, xb_03, region 

This is just another set of inputs similar to set 3. Here I selected the input associated with the most significant nonlinear features (`xw_01`).  

```{r}
viz_grid <- make_test_input_grid(my_inputs, df_preproc, c("xw_01", "xb_03"), "region")
```

**First model**  

```{r mod_2B3.4, out.width=800, fig.width=8, fig.asp=0.60, warning=FALSE}
make_post_pred(mod_2B3_2Ac3, viz_grid) %>%
  ggplot(aes(x=xw_01, fill=xb_03)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(region~xb_03) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "xb_03", breaks = NULL, labels = NULL)) +
  scale_fill_viridis_c() + ylab("log response")
```

- Increasing nonlinear predictor `xw_01` has increase response, but the scale is different across regions.  
- The nonlinear predictor `xb_03` increases response for regions `XX`,`YY` but not in `ZZ`.  

**Second model**  

```{r mod_2B1.4, out.width=800, fig.width=8, fig.asp=0.60, warning=FALSE}
make_post_pred(mod_2B1_2A3, viz_grid) %>%
  ggplot(aes(x=xw_01, fill=xb_03)) +
  geom_ribbon(aes(ymin = y_lwr, ymax = y_upr), alpha=0.6) +
  geom_ribbon(aes(ymin = trend_lwr, ymax = trend_upr), alpha=0.8, fill="grey") +
  geom_line(aes(y = trend_avg), size=0.5) +
  facet_grid(region~xb_03) +
  scale_x_continuous(sec.axis = sec_axis(~ . , name = "xb_03", breaks = NULL, labels = NULL)) +
  scale_fill_viridis_c() + ylab("log response")
```

- We see similar effect as with the prior comparisons, that the linear inputs only model is unable to fit more closely to observations in the specific region category.  

----

## Conclusions

- For the inputs that are visualized, whether predictive trends are consistent across the two models depends on what we examine.  
- The trends from simple additive linear predictors and categorical predictors are almost identical.  
- For inputs that involve interaction:
  - The model with interaction from `region` to continuous inputs is more capable of explaining the observed variation per `region` category, as compared to the model with no interaction.  
  - But this may cause higher risk of overfitting, when the observations are rare: in our data, when the inputs are at extreme values.  

----
