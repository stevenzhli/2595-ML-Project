---
title: "INFSCI 2595 Final Project"
subtitle: "Part 2D1, Regression - Resampling - LM"
author: "Zhenyu Li"
date: '2022-04-18'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_linedraw())
library(tidymodels)
tidymodels_prefer()
source("./scripts/utils.R")
```

```{r message=FALSE, warning=FALSE}
df <- readr::read_csv("./data/final_project_train.csv", col_names = TRUE)
df_regr <- df %>% select(-c(rowid,outcome)) # remove unused columns
```


## Linear Models

Train the 2 predefined linear models and 3 custom basis linear models selected from section 2A using resampling.  

**Create the blueprints for data preprocessing & feature engineering.**  

```{r preprocess}
bp_prep <- recipe(response ~ ., data=df_regr) %>% 
  step_log(all_outcomes()) %>% 
  step_center(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors())
  # prep(training=df_regr, retain=T) %>% bake(new_data=NULL)
```

### Predefined models

- `2D1`: All categorical and continuous inputs - linear additive features.

```{r mod_2D1}
bp_2D1 <- bp_prep %>% 
  step_dummy(all_nominal_predictors())
```

- `2D2`: All pairwise interactions of continuous inputs, include additive categorical features.
  
```{r mod_2D2}
bp_2D2 <- bp_prep %>% 
  step_interact( ~ all_numeric_predictors():all_numeric_predictors(), sep = ":") %>% 
  step_dummy(all_nominal_predictors())
```

### Custom models

- Import previous models that are referenced here.
- Get input names that need nonlinear features together.

```{r}
mod_2Ac1 <- readr::read_rds("./models/mod_2Ac1")
mod_2Ac3 <- readr::read_rds("./models/mod_2Ac3")
mod_2Ac4 <- readr::read_rds("./models/mod_2Ac4")

nonlin_pred <- c("xa_03","xa_05","xa_08",
                 "xb_03","xb_05","xb_08",
                 "xn_03","xn_05","xn_08",
                 "xs_01","xs_04","xs_06",
                 "xw_01","xw_02","xw_03")
```


- `2D3_2Ac1`: Linear additive of the nonlinear features and the rest. 

```{r mod_2D3}
bp_2D3_2Ac1 <- bp_prep %>% 
  step_ns(all_of(nonlin_pred), deg_free = 2) %>% 
  step_dummy(all_nominal_predictors())

# check # of features with corresponding model (+response -intercept)
bp_2D3_2Ac1 %>% prep(training=df_regr, retain=T) %>% bake(new_data=NULL) %>% ncol()
coef(mod_2Ac1) %>% length()
```

- `2D4_2Ac3`: Interact `region` with only the nonlinear features, additive for the rest.

```{r mod_2D4}
bp_2D4_2Ac3 <- bp_prep %>% 
  step_ns(all_of(nonlin_pred), deg_free = 2) %>% 
  step_dummy(region, one_hot = T) %>% 
  step_dummy(customer, one_hot = F) %>% 
  step_interact( ~ starts_with("region"):contains("_ns_"), sep = ":") %>% 
  # remove the additive nonlinear features and the regions
  step_rm(starts_with("x") & contains("_ns_")) %>% 
  step_rm(ends_with("XX"), ends_with("YY"), ends_with("ZZ"))

# check # of features with corresponding model (+response -intercept)
bp_2D4_2Ac3 %>% prep(training=df_regr, retain=T) %>% bake(new_data=NULL) %>% ncol()
coef(mod_2Ac3) %>% length()
```

- `2D5_2Ac4`: All pairwise interactions for all input variables.  

```{r mod_2D5}
bp_2D5_2Ac4 <- bp_prep %>% 
  step_interact( ~ all_numeric_predictors():all_numeric_predictors(), sep=":") %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact( ~ starts_with("region"):matches("^x.{1}_\\d+$"), sep=":") %>% 
  step_interact( ~ starts_with("customer"):matches("^x.{1}_\\d+$"), sep=":") %>% 
  step_interact( ~ matches("^region_.{2}$"):matches("^customer_.{1,6}$"), sep=":")
  
# check # of features with corresponding model (+response -intercept)
bp_2D5_2Ac4 %>% prep(training=df_regr, retain=T) %>% bake(new_data=NULL) %>% ncol()
coef(mod_2Ac4) %>% length()
```

----

## Resampling

### Setup

**Allow parallel processing.**  

```{r message=FALSE, warning=FALSE}
if(parallel::detectCores(logical=FALSE) > 3){
  library(doParallel)
  num_cores <- parallel::detectCores(logical=FALSE)
  cl <- makePSOCKcluster(num_cores - 2)
  registerDoParallel(cl)
}
```

**Define the resampling scheme.**

- Use 5 fold cross-validation with 5 repeats for resampling.
- Will compare RMSE, MAE and R-Squared metrics.
- Model specification: use `lm` engine to fit the models.

```{r resample setup}
set.seed(2543)
cv_folds <- vfold_cv(df_regr, v = 5, repeats = 5) 
my_metrics <- metric_set(rmse, mae, rsq)
lm_spec <- linear_reg() %>% set_engine("lm")
```

**Create workflow set to fit.**  

```{r workflow set}
lm_wset <- workflow_set(
  preproc = list(
    all_additive = bp_2D1,
    all_cont_pairwise = bp_2D2,
    nonlin_additive = bp_2D3_2Ac1,
    region_interact = bp_2D4_2Ac3,
    all_pairwise = bp_2D5_2Ac4
    ), 
  models = list(lm = lm_spec)
  )
```

### Execute

```{r message=FALSE, warning=FALSE}
tune_2D_lm <- lm_wset %>% 
  workflow_map(
    fn = "fit_resamples",
    resamples = cv_folds, 
    metrics = my_metrics,
    control = control_resamples(save_pred = F),
    verbose = T
  )
```

```{r save result}
readr::write_rds(tune_2D_lm,"./models/tune_2D_lm")
```


----

## Conclusions

```{r}
tune_2D_lm <- readr::read_rds("./models/tune_2D_lm")
```

### Performance

**Visualize and compare performances across 5 linear models.**

- Due to the extreme values of the two pairwise interaction models, the y-axis scale is set to log scale. 

```{r overview, out.width=700, fig.width=7, fig.asp=0.30, warning=FALSE}
tune_2D_lm %>% collect_metrics() %>% 
  ggplot(aes(x=wflow_id, color=wflow_id)) + 
  geom_linerange(aes(ymin=mean-std_err, ymax=mean+std_err))+
  geom_point(aes(y=mean), position = position_dodge(0.8)) +
  facet_wrap( ~ .metric, scales = "free_y") +
  scale_y_log10() +
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  labs(color="model")
```

- Remove both models with pairwise interactions from visualization, since they have extreme poor performances (`mod_2D2`, `mod2D5`).  

```{r zoom in, out.width=700, fig.width=7, fig.asp=0.30, warning=FALSE}
tune_2D_lm %>% collect_metrics() %>% 
  filter(!grepl("_pairwise_", wflow_id)) %>% 
  ggplot(aes(x=wflow_id, color=wflow_id)) + 
  geom_linerange(aes(ymin=mean-std_err,ymax=mean+std_err)) +
  geom_point(aes(y=mean), position = position_dodge(0.8)) +
  facet_wrap( ~ .metric, scales = "free_y") +
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank()) +
  labs(color="model")
```

- Judging from both MAE and RMSE, the best model should be the nonlinear additive model (green, `mod_2D3_2Ac1`). 
  - With RMSE, both all linear additive model (red, `mod_2D1`), and the nonlinear additive models are good. The model with `region` interaction to nonlinear features (blue, `mod_2D4_2Ac3`) resulted high RMSE. 
  - For R-Squared, there is no statistically significant difference between the three models. 

### Best Model

**Retrain the best model with resampling, and save predictions.**

```{r}
lm_best_wflow_mae <- "nonlin_additive_lm"

mod_2D_lm_best_wflow <- lm_wset %>% 
  extract_workflow(lm_best_wflow_mae)

mod_2D_lm_best_resample <- 
  mod_2D_lm_best_wflow %>% 
  fit_resamples(
    cv_folds,
    metrics = my_metrics,
    control = control_resamples(save_pred = T)
  )

mod_2D_lm_best_resample %>% collect_metrics() %>% select(-.config, -.estimator)
```

```{r}
save_models(mget(ls(pattern = "^mod_2D_lm")))
```

----
