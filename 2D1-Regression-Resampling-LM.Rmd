---
subtitle: "Part 2D1, Regression - Resampling - LM"
author: "Zhenyu Li"
date: '2022-04-18'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_linedraw())
library(tidymodels)
tidymodels_prefer()
source("./scripts/utils.R")
```

```{r message=FALSE, warning=FALSE}
df <- readr::read_csv("./data/final_project_train.csv", col_names = TRUE)
df_regr <- df %>% select(-c(rowid,outcome)) # remove rowid and outcome from training data
```
- I choose `tidymodels` to train and tune the models.

## Linear Models

### Feature Engineering

Create the blueprints for data preprocessing & feature engineering.  

#### Predefined linear models

- `2D1`: All categorical and continuous inputs - linear additive features.

```{r mod_2D1}
bp_2D1 <- recipe(response ~ ., data=df_regr) %>% 
  step_log(all_outcomes()) %>% 
  step_center(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors())
  # prep(training=df_regr, retain=T) %>% bake(new_data=NULL)
```

- `2D2`: All pairwise interactions of continuous inputs, include additive categorical features.
  
```{r mod_2D2}
bp_2D2 <- bp_2D1 %>% 
  step_interact( ~ all_numeric_predictors():all_numeric_predictors(), sep = ":")
```

#### Custom linear models: 3 models from 2A

- Import previous models that are referenced here.

```{r}
mod_2Ac1 <- readr::read_rds("./models/mod_2Ac1")
mod_2Ac3 <- readr::read_rds("./models/mod_2Ac3")
mod_2Ac4 <- readr::read_rds("./models/mod_2Ac4")
```

- Create vector of input names that need nonlinear features

```{r}
nonlin_pred <- c("xa_03","xa_05","xa_08",
                 "xb_03","xb_05","xb_08",
                 "xn_03","xn_05","xn_08",
                 "xs_01","xs_04","xs_06",
                 "xw_01","xw_02","xw_03")
```

- `2D3_2Ac1`: Linear additive of the nonlinear features and the rest. 

```{r mod_2D3}
bp_2D3_2Ac1 <- bp_2D1 %>% 
  step_ns(all_of(nonlin_pred), deg_free = 2) %>% 
  step_dummy(all_nominal_predictors())

# check # of features with corresponding model (+response -intercept)
bp_2D3_2Ac1 %>% prep(training=df_regr, retain=T) %>% bake(new_data=NULL) %>% ncol()
coef(mod_2Ac1) %>% length()
```

- `2D4_2Ac3`: Interact `region` with only the nonlinear features, additive for the rest.

```{r mod_2D4}
bp_2D4_2Ac3 <- bp_2D1 %>% 
  step_ns(all_of(nonlin_pred), deg_free = 2) %>% 
  step_dummy(region, one_hot = T) %>% 
  step_dummy(customer, one_hot = F) %>% 
  step_interact( ~ starts_with("region"):contains("_ns_"), sep = ":") %>% 
  step_rm(starts_with("x") & contains("_ns_")) %>% 
  step_rm(ends_with("XX"), ends_with("YY"), ends_with("ZZ"))

# check # of features with corresponding model (+response -intercept)
bp_2D4_2Ac3 %>% prep(training=df_regr, retain=T) %>% bake(new_data=NULL) %>% ncol()
coef(mod_2Ac3) %>% length()
```

- `2D5_2Ac4`: All pairwise interactions for all input variables. (`mod_2Ac4`)

```{r mod_2D5}
bp_2D5_2Ac4 <- bp_2D1 %>% 
  step_interact( ~ all_predictors():all_predictors(), sep=":") %>% 
  step_dummy(all_nominal_predictors())

# check # of features with corresponding model (+response -intercept)
bp_2D5_2Ac4 %>% prep(training=df_regr, retain=T) %>% bake(new_data=NULL) %>% ncol()
coef(mod_2Ac4) %>% length()
```


### Training

#### Training Setup

- Resampling Scheme
  - Use 5 fold, 5 repeated cross-validation
  - Will compare RMSE, MAE and R-Squared

```{r cv setup}
set.seed(2543)
cv_folds <- vfold_cv(df_regr, v = 5, repeats = 5) 
my_metrics <- metric_set(rmse, mae, rsq)
```

- Model Specification
  - Use `lm` engine

```{r model setup}
lm_model <- linear_reg() %>% set_engine("lm")
```

- Create workflow set for the linear models to train. 

```{r workflowset}
bp_set_lm <- list(
  all_additive = bp_2D1,
  all_cont_pairwise = bp_2D2,
  nonlin_additive = bp_2D3_2Ac1,
  region_interact = bp_2D4_2Ac3,
  all_pairwise = bp_2D5_2Ac4
)
wf_set_lm <- workflow_set(preproc = bp_set_lm, models = list(lm = lm_model))
```

#### Start Training

- Operate on the workflow set to perform fitting and cross-validation. 

```{r resampling}
cv_lm <- wf_set_lm %>% 
  workflow_map(
    fn = "fit_resamples",
    resamples = cv_folds, 
    metrics = my_metrics,
    control = control_resamples(save_pred = T)
  )
```

### Conclusions

- Visualize and compare performances across 5 linear models.
  - Due to the extreme values of the two pairwise interaction models, the y-axis scale is set to log scale. 

```{r out.width=500, fig.width=5, fig.asp=0.30, warning=FALSE}
cv_lm %>% collect_metrics() %>% 
  ggplot(aes(x=wflow_id, color=wflow_id)) + 
  geom_linerange(aes(ymin=mean-std_err, ymax=mean+std_err))+
  geom_point(aes(y=mean), position = position_dodge(0.8)) +
  facet_wrap( ~ .metric, scales = "free_y") +
  scale_y_log10() +
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
```

- Remove both models with pairwise interactions from visualization, since they have extreme poor performances (`mod_2D2`, `mod2D5`).  

```{r out.width=500, fig.width=5, fig.asp=0.30, warning=FALSE}
cv_lm %>% collect_metrics() %>% 
  filter(!grepl("_pairwise_", wflow_id)) %>% 
  ggplot(aes(x=wflow_id, color=wflow_id)) + 
  geom_linerange(aes(ymin=mean-std_err,ymax=mean+std_err)) +
  geom_point(aes(y=mean), position = position_dodge(0.8)) +
  facet_wrap( ~ .metric, scales = "free_y") +
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())
```

- Judging from both MAE and RMSE, the best model should be the nonlinear additive model (green, `mod_2D3_2Ac1`). 
  - With RMSE, both all linear additive model (red, `mod_2D1`), and the nonlinear additive models are good. The model with `region` interaction to nonlinear features (blue, `mod_2D4_2Ac3`) resulted high RMSE. 
  
----


