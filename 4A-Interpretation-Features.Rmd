---
title: "INFSCI 2595 Final Project"
subtitle: "Part 4A, Interpretation - Features"
author: "Zhenyu Li"
date: '2022-04-24'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_packages, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_linedraw())
library(tidymodels)
tidymodels_prefer()
library(vip)
source("./scripts/utils.R")
```


```{r message=FALSE, warning=FALSE}
df <- readr::read_csv("./data/final_project_train.csv", col_names = TRUE)
df_regr <- df %>% select(-c(rowid, outcome)) %>% mutate(response = log(response))
df_clas <- df %>% select(-c(rowid, response))
```

----

Tasks

- Identify the best model for the regression and classification tasks

- Identify the most important features/variables associated with best performing model for the regression and classification tasks
  - Are the most important variables similar for regression and classification tasks?
  - Does one of the sentiment derived feature types “dominate” the most important variables?
  - Does one of the sentiment derived feature types appear to be not helpful at all?
  - Does the formulation of the problem help with answer the questions
    - Based on your modeling results, do you feel these sentiment derived features are helpful at predicting the outputs?
    - Essentially, do you feel the model results are “good” and was I right about the relationship between report sentiment and the outputs?

----

## Best models

The best model for the **regression task** was identified in part 2D4 as the Elastic Net model.  
The best model for the **classification task** was identified in part 3D4 as the Elastic Net model.  


**Read in the respective best model for each task.**  

```{r}
mod_regr <- readr::read_rds("./models/mod_2D_enet_best_wflow") 
mod_regr_fit <- mod_regr %>% fit(df_regr)

mod_clas <- readr::read_rds("./models/mod_3D_enet_best_wflow") 
mod_clas_fit <- mod_clas %>% fit(df_clas)
```

----

## Feature Importance

**Plot the top 20 most important features for each model and discuss.**  

### Regression

- For the regression model, since we are predicting time spent on sale, sentiment derived inputs that are associated with longer communications, or stronger responses from a customer (e.g. very positive, very negative), are expected to be important to predict the sale time.  

**First examine all coefficients.**

```{r}
mod_regr_fit %>%
  extract_fit_parsnip() %>%
  vip(500, lambda = mod_regr$param$penalty) +
    ggtitle("regression: elastic net")
```

**Check the top 20 coefficients.**

```{r}
mod_regr_fit %>%
  extract_fit_parsnip() %>%
  vip(20, lambda = mod_regr$param$penalty) +
    ggtitle("regression: elastic net")
```

- From my regression model:
  - The categorical input `region` appears to be an important predictor of conversation length. 
  - Interaction of `customer` to some sentiment features are important. 
    - For those sentiment features, we see `xa_`, `xb_`, `xw_` at high ranks. 
    - It appears different lexicon derived features are important at predicting different customers. 
  - For continuous input, word count derived feature `xw_01` is the most important. 
  - Features from `xs_` set is rare in the top ranked inputs. 

### Classification

- For the classification model, inputs that can reflect true intention of customer to purchase, or if a customer is interested in a product or not, could be more effective in predicting the `outcome` of a sale.  

**First examine all coefficients.**

```{r}
mod_clas_fit %>% 
  extract_fit_parsnip() %>%
  vip(500, lambda = mod_clas$param$penalty) +
    ggtitle("classification: elastic net")
```

**Check the top 20 coefficients.**

```{r}
mod_clas_fit %>% 
  extract_fit_parsnip() %>%
  vip(20, lambda = mod_clas$param$penalty) +
    ggtitle("classification: elastic net")
```

- From my classification model:
  - The notable sentiment derived features are the `xn_` set of inputs, which "dominates" the highest ranks in my classification model.  
  - Other sentiment derived inputs include mostly `xw_`, `xa_`,`xb_` interacting with the `customer`.  
  - We see rare `xs_` inputs and no `xw_01` input from the top ranked features.  

----

## Conclusions

- We see the set of important features for the regression and classification tasks are **different**. Though there are some **common inputs** that appear to be important in both models. The importance of such common features are different too. These are expected because we are predicting different things that are somewhat related.  

- The formulation of the problem is mostly helpful to answer the questions.  
  - In the regression task, most sentiment derived features require interaction with categorical inputs to predict the length of sale time. The word count feature `xw_01` appears to be only top ranked features without reliance on the interaction. 
  - In the classification task, many sentiment derived features are helpful to predict failing the product sale goal. Notable ones are those from the NRC lexicon (`xn`).  
  - The features derived from `sentimentr` appear to be least helpful in both tasks.

- The models developed do have certain limitations.
  - Both my best regression and classification models depend highly on the customer categorical input. 
  - This may prevent the models from working well with new customers. Ideally the model should rely on the sentiment derived features only to predict the outcomes. 

----
